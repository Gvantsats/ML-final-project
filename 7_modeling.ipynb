{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "import scipy.ndimage\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "\n",
    "    def __init__(self , n_inputs):\n",
    "        self.label_names = ['უ', 'ყ', 'მ', 'შ', 'ძ', 'წ', 'ს', 'ხ', 'ლ', 'ჩ' , '-']\n",
    "        # learning info\n",
    "        self.n_iterations = 100000\n",
    "        self.l_rate = 0.001\n",
    "        # layer info\n",
    "        self.l_sizes = [n_inputs, 3 , 1]\n",
    "        self.n_layer = len(self.l_sizes)\n",
    "        # generating biases and weights on every hidden layer\n",
    "        self.biases = [np.random.randn(i, 1) for i in self.l_sizes[1:]]\n",
    "        self.weights = [np.random.randn(j, i) for i, j in zip(self.l_sizes[:-1], self.l_sizes[1:])]\n",
    "\n",
    "    # Activation function\n",
    "    def sigmoid(self, s):\n",
    "        return 1.0 / (np.exp(-s) + 1.0)\n",
    "\n",
    "    # Derivative of activation function\n",
    "    def sigmoid_der(self, s):\n",
    "        return self.sigmoid(s) * (1.0 - self.sigmoid(s))\n",
    "\n",
    "    # Forward propagation\n",
    "    def forward(self, data):\n",
    "        data = data.reshape(data.shape[0] , 1)\n",
    "        curr = data\n",
    "        for i in range(len(self.biases)):\n",
    "            bias = self.biases[i]\n",
    "            weight = self.weights[i]\n",
    "            mult = np.dot(weight , curr)\n",
    "            curr = self.sigmoid(mult + bias)\n",
    "        \n",
    "        return curr\n",
    "\n",
    "    # Backward propagation\n",
    "    def backward(self, X, y):\n",
    "        X = X.reshape(X.shape[0] , 1)\n",
    "        biases_err = [np.zeros((i, 1)) for i in self.l_sizes[1:]]\n",
    "        weights_err = [np.zeros((j, i)) for i, j in zip(self.l_sizes[:-1], self.l_sizes[1:])]\n",
    "        \n",
    "        # forward propagation while saving a and z values\n",
    "        a = [X]\n",
    "        z = []\n",
    "        for i in range(len(self.biases)):\n",
    "            bias = self.biases[i]\n",
    "            weight = self.weights[i]\n",
    "            curr = a[-1]\n",
    "            mult = np.dot(weight , curr)\n",
    "            z.append(mult + bias)\n",
    "            curr = self.sigmoid(mult + bias)\n",
    "            a.append(curr)\n",
    "\n",
    "        # backpropagation\n",
    "        loss = (a[-1] - y) * self.sigmoid_der(z[-1])\n",
    "        weights_err[-1] = np.dot(loss, a[-2].transpose())\n",
    "        biases_err[-1] = loss\n",
    "        \n",
    "        for i in range(2 , self.n_layer):\n",
    "            loss = np.dot(self.weights[-i + 1].transpose(), loss) * self.sigmoid_der(z[-i])\n",
    "            weights_err[-i] = np.dot(loss, a[-i - 1].transpose())\n",
    "            biases_err[-i] = loss\n",
    "\n",
    "        #update weights and biases\n",
    "        for i in range(len(self.biases)):\n",
    "            self.weights[i] -= self.l_rate * weights_err[i]\n",
    "            self.biases[i] -= self.l_rate * biases_err[i]\n",
    "\n",
    "    def training(self, data):\n",
    "        for i in range(self.n_iterations):\n",
    "            for j in range(len(data)):\n",
    "                X = data[j][0]\n",
    "                y = data[j][1]\n",
    "                self.backward(X , y)\n",
    "                \n",
    "    def classify(self , data):\n",
    "        ans = self.forward(data)[0]\n",
    "        res = [0] * len(ans)\n",
    "        ind = -1\n",
    "        for i in range(len(ans)):\n",
    "            if ans[i] > 0.5:\n",
    "                res[i] = 1\n",
    "                ind = i\n",
    "                else\n",
    "                res[i] = 0\n",
    "        if (sum res > 1):\n",
    "            return '-'\n",
    "        return self.label_names[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataObject:\n",
    "    # These are variables to prevent adding the same feature twice accidently.\n",
    "    ROTATE = False\n",
    "    SCALE = False\n",
    "    BLUR = False\n",
    "    NOISE = False\n",
    "\n",
    "    def __init__(self, image):\n",
    "        self.image_arr = image\n",
    "\n",
    "    def get_array(self, shape=(6,)):\n",
    "        return self.image_arr.flatten().reshape(shape)\n",
    "\n",
    "    def set_parent_features(self, parent_obj):\n",
    "        self.ROTATE = parent_obj.ROTATE\n",
    "        self.SCALE = parent_obj.SCALE\n",
    "        self.BLUR = parent_obj.BLUR\n",
    "        self.NOISE = parent_obj.NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingDataFrame:\n",
    "\n",
    "    data = {}\n",
    "    letters = []\n",
    "    DEFAULT_COLOR = 255.0\n",
    "\n",
    "    # If images are white on black, pass false as a first argument, please.\n",
    "    def __init__(self, black_on_white=True, root_dir=\"./data/ასოები/\", height=25, width=25):\n",
    "        self.HEIGHT = height\n",
    "        self.WIDTH = width\n",
    "        self.add_data(root_dir, black_on_white)\n",
    "\n",
    "    # Taking parent (children of root_dir) folder names as labels, they should be only 1 letter long.\n",
    "    # Data should be in labeled letter folders.\n",
    "    # If images are white on black, pass false as a second argument, please.\n",
    "    def add_data(self, root_dir, black_on_white=True):\n",
    "        for letter in listdir(root_dir):\n",
    "            if len(letter) > 1:\n",
    "                continue\n",
    "            for image_name in listdir(root_dir + letter):\n",
    "                img = cv2.imread(root_dir + letter + \"/\" + image_name, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is None:\n",
    "                    print(\"wrong image path\")\n",
    "                else:\n",
    "                    if not black_on_white:\n",
    "                        img = 255 - img\n",
    "                        self.DEFAULT_COLOR = 0.0\n",
    "                    resized_img = cv2.resize(img, dsize=(self.WIDTH, self.HEIGHT), interpolation=cv2.INTER_CUBIC)\n",
    "                    if letter not in self.data:\n",
    "                        self.data[letter] = []\n",
    "                        self.letters.append(letter)\n",
    "                    self.data[letter].append(DataObject(resized_img))\n",
    "\n",
    "    # Rotate alphas are angles.\n",
    "    def add_rotate_f(self, rotate_alphas=(-20, -10, -5, 5, 10, 20)):\n",
    "        rotate_alphas = list(set(rotate_alphas))\n",
    "        rotate_alphas = [i for i in rotate_alphas if i % 360 != 0]  # removes angles which are useless\n",
    "        if len(rotate_alphas) == 0:\n",
    "            return\n",
    "        for letter in self.letters:\n",
    "            appendix = []\n",
    "            for sample in self.data[letter]:\n",
    "                if not sample.ROTATE:\n",
    "                    sample.ROTATE = True\n",
    "                    for angle in rotate_alphas:\n",
    "                        new_sample = scipy.ndimage.interpolation.rotate(sample.get_array(), angle,\n",
    "                                                                        mode='constant',\n",
    "                                                                        cval=self.DEFAULT_COLOR,\n",
    "                                                                        reshape=False)\n",
    "                        new_dataobject = DataObject(new_sample)\n",
    "                        new_dataobject.set_parent_features(sample)  # To prevent accidently using same feature twice.\n",
    "                        appendix.append(new_dataobject)\n",
    "            self.data[letter].extend(appendix)\n",
    "\n",
    "    # Scale alphas are pixels to add edges (then resize to original size).\n",
    "    # Warning: alphas that are bigger than 3 or smaller than -3 . passing them would cause an error.\n",
    "    def add_scale_f(self, scale_alphas=(3, 2, 1, -1, -2, -3)):\n",
    "        scale_alphas = list(set([int(i) for i in scale_alphas]))\n",
    "        if 0 in scale_alphas:\n",
    "            scale_alphas.remove(0)\n",
    "        if len(scale_alphas) == 0:\n",
    "            return\n",
    "        for alpha in scale_alphas:\n",
    "            assert -4 <= alpha <= 4\n",
    "            if not -4 <= alpha <= 4:\n",
    "                print(str(alpha) + \" is forbidden, please pass correct scale alphas\")\n",
    "                return\n",
    "        for letter in self.letters:\n",
    "            appendix = []\n",
    "            for sample in self.data[letter]:\n",
    "                if not sample.SCALE:\n",
    "                    sample.SCALE = True\n",
    "                    for pixels in scale_alphas:\n",
    "                        if pixels > 0:\n",
    "                            new_sample = np.c_[np.full((self.HEIGHT + 2 * pixels, pixels), self.DEFAULT_COLOR),\n",
    "                                               np.r_[np.full((pixels, self.WIDTH), self.DEFAULT_COLOR),\n",
    "                                                     sample.get_array(),\n",
    "                                                     np.full((pixels, self.WIDTH), self.DEFAULT_COLOR)],\n",
    "                                               np.full((self.HEIGHT + 2 * pixels, pixels), self.DEFAULT_COLOR)]\n",
    "                        else:\n",
    "                            pixels *= -1\n",
    "                            new_sample = sample.get_array()[pixels:-pixels, pixels:-pixels]\n",
    "                        new_sample = cv2.resize(new_sample, dsize=(self.WIDTH, self.HEIGHT),\n",
    "                                                interpolation=cv2.INTER_CUBIC)\n",
    "                        new_dataobject = DataObject(new_sample)\n",
    "                        new_dataobject.set_parent_features(sample)  # To prevent accidently using same feature twice.\n",
    "                        appendix.append(new_dataobject)\n",
    "            self.data[letter].extend(appendix)\n",
    "\n",
    "    # Sigmas are values for blur coefficient. How much pixels should be interpolated to neighbour pixels.\n",
    "    # Please keep values between 0 < sigma < 1.\n",
    "    def add_blur_f(self, sigmas=(.1, .5)):\n",
    "        sigmas = list(set(sigmas))\n",
    "        sigmas = [i for i in sigmas if 0 < i < 1]  # removes values which are forbidden\n",
    "        if len(sigmas) == 0:\n",
    "            return\n",
    "        for letter in self.letters:\n",
    "            appendix = []\n",
    "            for sample in self.data[letter]:\n",
    "                if not sample.BLUR:\n",
    "                    sample.BLUR = True\n",
    "                    for sigma in sigmas:\n",
    "                        new_sample = scipy.ndimage.gaussian_filter(sample.get_array(), sigma=sigma)\n",
    "                        new_dataobject = DataObject(new_sample)\n",
    "                        new_dataobject.set_parent_features(sample)  # To prevent accidently using same feature twice.\n",
    "                        appendix.append(new_dataobject)\n",
    "            self.data[letter].extend(appendix)\n",
    "\n",
    "    # noise is maximum value added or decreased(max.:100), dots are how many dots are changed.\n",
    "    def add_noise_f(self, noise=20, dots=10):\n",
    "        if dots < 1 or 0 < noise < 100:\n",
    "            return\n",
    "        for letter in self.letters:\n",
    "            appendix = []\n",
    "            for sample in self.data[letter]:\n",
    "                if not sample.NOISE:\n",
    "                    sample.NOISE = True\n",
    "                    new_sample = np.copy(sample.get_array())\n",
    "                    for _ in range(dots):\n",
    "                        x = random.randint(0, self.WIDTH - 1)\n",
    "                        y = random.randint(0, self.HEIGHT - 1)\n",
    "                        if new_sample[y][x] > 200:\n",
    "                            noise *= -1\n",
    "                        elif new_sample[y][x] > 50:\n",
    "                            noise = random.randint(-noise, noise)\n",
    "                        new_sample[y][x] = new_sample[y][x] + noise\n",
    "                    new_dataobject = DataObject(new_sample)\n",
    "                    new_dataobject.set_parent_features(sample)  # To prevent accidently using same feature twice.\n",
    "                    appendix.append(new_dataobject)\n",
    "            self.data[letter].extend(appendix)\n",
    "\n",
    "    def get_random(self, letter):\n",
    "        return random.choice(self.data[letter])\n",
    "\n",
    "    def get_letter_list(self, letter):\n",
    "        return self.data[letter]\n",
    "\n",
    "    def get_letters(self):\n",
    "        return self.letters\n",
    "\n",
    "    def describe(self):\n",
    "        print(\"data contains \" + str(len(self.letters)) + \"letters, \")\n",
    "        total = 0\n",
    "        for letter in self.letters:\n",
    "            amount = len(self.data[letter])\n",
    "            total += amount\n",
    "            print(str(amount) + \" - \" + letter + \"'s.\")\n",
    "        print(\"\\nTOTAL: \" + str(total) + \" letters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
